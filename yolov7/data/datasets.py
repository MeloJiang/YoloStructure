# Datasets
import glob
import json
import logging
import math
import os
import os.path as osp
import hashlib
import random
import shutil
import time
from itertools import repeat
from multiprocessing.pool import Pool
from pathlib import Path
from threading import Thread

import cv2
import numpy as np
import torch
import torch.nn.functional as F
from PIL import ExifTags, Image, ImageOps
from torch.utils.data import Dataset
from tqdm import tqdm

from yolov7.utils.events import load_yaml
from yolov7.data.data_augment import augment_hsv, mosaic_augmentation, mix_up, letterbox


# Parameters
help_url = 'https://github.com/ultralytics/yolov5/wiki/Train-Custom-Data'
IMG_FORMATS = ['bmp', 'jpg', 'jpeg', 'png', 'tif', 'tiff', 'dng', 'webp', 'mpo']  # acceptable image suffixes
VID_FORMATS = ['mov', 'avi', 'mp4', 'mpg', 'mpeg', 'm4v', 'wmv', 'mkv']  # acceptable video suffixes

# Get orientation exif tag
for k, v in ExifTags.TAGS.items():
    if v == "Orientation":
        orientation = k
        break


class LoadImagesAndLabels(Dataset):
    """ç”¨äºåˆ›å»ºè®­ç»ƒã€æµ‹è¯•ç”¨çš„æ•°æ®é›†"""
    def __init__(self, path, img_size=640, batch_size=16, augment=False, hyp=None, task='val',
                 rect=False, image_weights=False, cache_images=False, single_cls=False, data_dict=None,
                 stride=32, pad=0.0, prefix='', rank=-1, check_images=False, check_labels=False):
        assert task.lower() in ("train", "val", "test", "speed"), f"Not supported task: {task}"
        t1 = time.time()
        # å›¾ç‰‡çš„åˆå§‹åŒ–ä¿¡æ¯
        self.path = path
        self.img_size = img_size
        self.image_weights = image_weights

        # å›¾ç‰‡å¢å¼ºç­‰å¤„ç†çš„å‚æ•°
        self.stride = stride
        self.pad = pad
        self.batch_size = batch_size
        self.augment = augment
        self.hyp = hyp

        # æœ‰å…³äºæœ¬æ•°æ®é›†çš„cacheè·¯å¾„ä¿¡æ¯
        self.valid_img_record = None

        # æ˜¯å¦æ£€æŸ¥å›¾ç‰‡å’Œæ ‡ç­¾çš„æ ‡è®°å€¼(boolean)
        self.check_images = check_images
        self.check_labels = check_labels

        # å½“å‰è¿›ç¨‹å·çš„æ ‡è®°
        self.rank = rank
        self.rect = False if image_weights else rect
        self.task = task

        # ä¸€ç§å›¾ç‰‡æ•°æ®å¢å¹¿çš„æ–¹å¼ï¼Œå°†å››å¼ ä¸åŒçš„å›¾ç‰‡æ‹¼æ¥æˆä¸€æ•´å¼ 
        self.mosaic = self.augment and not self.rect
        self.main_process = self.rank in (-1, 0)
        self.data_dict = data_dict
        self.class_name = data_dict["names"]
        self.img_paths, self.labels, self.img_info = self.get_images_and_labels(img_dir=path)

        # å¯¹äºå›¾ç‰‡rectçš„å¤„ç†ï¼š
        if self.rect:
            assert self.img_info, "WRONG! img_info is NULL!"
            shapes = [self.img_info[p]["shape"] for p in self.img_paths]
            self.shapes = np.array(shapes, dtype=np.float64)
            self.batch_indices = np.floor(
                np.arange(len(shapes)) / self.batch_size
            ).astype(np.int_)
            self.batch_shapes = self.sort_files_shapes()

        t2 = time.time()
        if self.main_process:
            print("âœ…Dataset initialization completed in {:.2f}s.".format(t2 - t1))

    def __len__(self):
        """è·å–æ•°æ®é›†çš„é•¿åº¦"""
        return len(self.img_paths)

    def __getitem__(self, index):
        """
        æ ¹æ®ç»™å®šindexæ¥è·å–å¯¹åº”çš„æ•°æ®æ ·æœ¬ï¼Œ
        è¯¥å‡½æ•°åœ¨è®­ç»ƒé›†æƒ…å†µä¸‹ä½¿ç”¨é©¬èµ›å…‹å›¾ç‰‡å¢å¼ºæŠ€æœ¯ä»¥åŠæ··åˆå¢å¼ºæŠ€æœ¯ï¼Œè€Œ
        åœ¨éªŒè¯æ•°æ®çš„æƒ…å†µä¸‹ä½¿ç”¨letterboxå›¾ç‰‡å¢å¼ºæŠ€æœ¯
        """
        # é©¬èµ›å…‹å›¾ç‰‡æ•°æ®å¢å¼º
        if self.augment and random.random() < self.hyp["mosaic"]:
            img, labels = self.get_mosaic(index)
            shapes = None
            # Mix upå›¾ç‰‡æ•°æ®å¢å¼º
            if random.random() < self.hyp["mixup"]:
                # å†åˆ›é€ ä¸€ä¸ªé©¬èµ›å…‹å›¾ç‰‡å¢å¼ºæ ·æœ¬å‡ºæ¥
                img_other, labels_other = self.get_mosaic(
                    random.randint(0, len(self.img_paths) - 1)
                )
                # å’Œå‰é¢çš„é©¬èµ›å…‹å›¾ç‰‡å¢å¼ºæ ·æœ¬åˆå¹¶ï¼Œå¾—åˆ°MixUpå›¾ç‰‡å¢å¼ºæ ·æœ¬
                img, labels = mix_up(img, labels, img_other, labels_other)

        else:
            # -------------------------------------------------------------------------
            # åŠ è½½å›¾ç‰‡..., self.load_imageåªæ˜¯å•çº¯åœ°æŠŠå›¾ç‰‡åŠ è½½æˆnpæ•°ç»„ï¼Œä¸åŒ…å«ä»»ä½•å›¾ç‰‡æ•°æ®å¢å¼ºæ“ä½œ
            # self.load_image ä¼šæŠŠåŸç”Ÿå›¾ç‰‡ç­‰æ¯”ä¾‹resizeæˆæœ€é•¿è¾¹ç­‰äºé¢„è®¾å€¼ï¼ˆ640ï¼‰çš„å¤§å°
            # h0w0 æ˜¯å›¾ç‰‡çš„åŸå§‹å°ºå¯¸ï¼Œè€Œhwå°±æ˜¯å›¾ç‰‡ç»è¿‡resizeä¹‹åçš„å°ºå¯¸(ä¸€èˆ¬ä¸ºé¢„è®¾å€¼:æœ€é•¿è¾¹ä¸º640)
            # -------------------------------------------------------------------------
            if self.hyp and "test_load_size" in self.hyp:
                img, (h0, w0), (h, w) = self.load_image(index, self.hyp["test_load_size"])
            else:
                img, (h0, w0), (h, w) = self.load_image(index)

            # letterboxå˜æ¢(å…¶å®å°±æ˜¯å°†å›¾ç‰‡å¡«å……æˆæ­£æ–¹å½¢ï¼Œè¾¹é•¿ä¸ºç»™å®šçš„img_size)
            shape = (
                self.batch_shapes[self.batch_indices[index]]
                if self.rect else self.img_size
            )  # å¦‚æœä¸é‡‡ç”¨rectæ¨¡å¼ï¼Œå°±ä½¿ç”¨é¢„è®¾çš„img_sizeæ¥ä½œä¸ºéªŒè¯é›†å›¾ç‰‡å¡«å……æˆçš„æ­£æ–¹å½¢çš„è¾¹é•¿

            # ---------------------------------------------------------
            # æ£€æŸ¥å‚æ•°å­—å…¸ï¼Œçœ‹æ˜¯å¦è¦æ±‚è¿”å›æ•´å‹çš„å¡«å……æ•°å€¼ï¼š
            # padæ˜¯æŒ‡å¡«å……æˆç»™å®šè¾¹é•¿çš„æ­£æ–¹å½¢çš„ä¸Šä¸‹å·¦å³çš„å¡«å……å€¼
            # æ³¨æ„ï¼Œè¿™é‡Œè¾“å…¥çš„imgçš„å°ºå¯¸å·²ç»ç»è¿‡äº†resize
            # ---------------------------------------------------------
            if self.hyp and "letterbox_return_int" in self.hyp:
                img, ratio, pad = letterbox(img, shape, auto=False, scaleup=self.augment,
                                            return_int=self.hyp["letterbox_return_int"])
            else:
                img, ratio, pad = letterbox(img, shape, auto=False, scaleup=self.augment)

            # ---------------------------------------------------------
            # shapesçš„è¾“å‡ºå†…å®¹çš„è§£æï¼š
            #       1. (h0, w0): è¡¨ç¤ºçš„æ˜¯åŸå§‹å›¾ç‰‡çš„é«˜å’Œå®½
            #       2.
            shapes = (h0, w0), ((h * ratio / h0, w * ratio / w0), pad)  # COCO mAP rescaling

            labels = self.labels[index].copy()
            if labels.size:
                # å°†resizeåçš„å°ºå¯¸hw * é¢„è®¾è¾¹é•¿å’ŒåŸå§‹è¾¹é•¿çš„æ¯”å€¼ratio åï¼Œèµ‹å€¼ç»™hw
                w *= ratio  # ratioæ˜¯æŒ‡letterboxæŒ‡å®šå°ºå¯¸å’Œload_imageåŠ è½½è¿›æ¥çš„å›¾ç‰‡å°ºå¯¸çš„æ¯”å€¼
                h *= ratio  # load_imageåŠ è½½å‡ºæ¥çš„å›¾ç‰‡é«˜å®½ä¹˜ä¸Šratioå¯ä»¥è°ƒæ•´ä¸ºletterboxä¸‹çš„å°ºå¯¸
                # æ–°çš„é”šæ¡†
                boxes = np.copy(labels[:, 1:])
                # åæ ‡çš„ä¸­å¿ƒç‚¹çš„xåæ ‡å‡å» width / 2ï¼Œå†ä¹˜ä¸Šæ•´ä¸ªå›¾ç‰‡çš„å®½åº¦ï¼Œå°±å¯ä»¥å¾—åˆ°å·¦ä¸Šè§’çš„æ¨ªåæ ‡ï¼ˆåˆ«å¿˜äº†æ·»åŠ å¡«å……å€¼ï¼‰
                # æ³¨æ„ï¼Œcocoæ•°æ®é›†çš„åæ ‡åˆ†åˆ«æ˜¯ ä¸­å¿ƒç‚¹xï¼Œä¸­å¿ƒç‚¹yï¼Œæ¡†å®½ï¼Œæ¡†é«˜(å…¨éƒ¨éƒ½æ˜¯ç›¸å¯¹äºæ•´å¼ å›¾ç‰‡ï¼Œå› æ­¤å–å€¼0~1)

                """
                ä¹‹æ‰€ä»¥è¦åŠ ä¸Špadçš„å€¼ï¼š
                    å‡è®¾æœ‰å¦‚ä¸‹çš„æƒ…å†µï¼Œå›¾ç‰‡çš„å¤§å°ä¸º 640 * 480, ç»è¿‡letterboxå¡«å……æˆ 640 * 640
                    é‚£ä¹ˆå°±ä¼šåœ¨å›¾ç‰‡çš„widthä¸¤è¾¹åˆ†åˆ«åŠ ä¸Šå¤§å°ä¸º pad=80 çš„å¡«å……
                    å‡è®¾åŸå›¾çš„é”šæ¡†å·¦ä¸Šè§’çš„åæ ‡ç‚¹ä¸º x=0.2, y=0.3 (è¡¨ç¤ºåæ ‡ç‚¹å¤„äºæ•´å¼ å›¾ç‰‡é«˜å’Œå®½çš„æ¯”ä¾‹ä½ç½®)
                    å› ä¸ºå›¾ç‰‡çš„ä¸¤è¾¹ç»è¿‡å¡«å……ï¼Œå› æ­¤è®¡ç®—å®é™…åƒç´ ä½ç½®æ—¶ä¸ºï¼š80 + 0.3 * 480
                """
                # åæ ‡çš„ä¸­å¿ƒç‚¹çš„xåæ ‡å‡å» width / 2ï¼Œå†ä¹˜ä¸Šæ•´ä¸ªå›¾ç‰‡çš„å®½åº¦ï¼Œå°±å¯ä»¥å¾—åˆ°å·¦ä¸Šè§’çš„æ¨ªåæ ‡
                boxes[:, 0] = (
                        w * (labels[:, 1] - labels[:, 3] / 2) + pad[0]
                )  # å·¦ä¸Šè§’çš„æ¨ªåæ ‡ x å–å€¼

                # åæ ‡çš„ä¸­å¿ƒç‚¹çš„yåæ ‡å‡å» height / 2ï¼Œå†ä¹˜ä¸Šæ•´ä¸ªå›¾ç‰‡çš„é«˜åº¦ï¼Œå°±å¯ä»¥å¾—åˆ°å·¦ä¸Šè§’çš„çºµåæ ‡
                boxes[:, 1] = (
                        h * (labels[:, 2] - labels[:, 4] / 2) + pad[1]
                )  # å·¦ä¸Šè§’çš„çºµåæ ‡ y å–å€¼

                # åæ ‡çš„ä¸­å¿ƒç‚¹xåæ ‡åŠ ä¸Š width / 2ï¼Œå†ä¹˜ä¸Šæ•´ä¸ªå›¾ç‰‡çš„å®½åº¦ï¼Œå°±å¯ä»¥å¾—åˆ°å³ä¸‹è§’çš„æ¨ªåæ ‡
                boxes[:, 2] = (
                        w * (labels[:, 1] + labels[:, 3] / 2) + pad[0]
                )  # å³ä¸‹è§’çš„æ¨ªåæ ‡ x å–å€¼

                # åæ ‡çš„ä¸­å¿ƒç‚¹çš„yåæ ‡åŠ ä¸Š height / 2ï¼Œå†ä¹˜ä¸Šæ•´ä¸ªå›¾ç‰‡çš„é«˜åº¦ï¼Œå°±å¯ä»¥å¾—åˆ°å³ä¸‹è§’çš„çºµåæ ‡
                boxes[:, 3] = (
                        h * (labels[:, 2] + labels[:, 4] / 2) + pad[1]
                )  # å³ä¸‹è§’çš„çºµåæ ‡ y å–å€¼
                labels[:, 1:] = boxes

        """
        è¿™ä¸€æ­¥æ“ä½œçš„ç›®çš„æ˜¯å°†labelsçš„å¯¹è§’åæ ‡å½¢å¼é‡æ–°è½¬æ¢æˆä¸­å¿ƒå®½é«˜æ¨¡å¼
        å³ï¼š[x1, y1, x2, y2] --> [x_center, y_center, width, height]
        å¹¶ä¸”ä¸­å¿ƒå®½é«˜æ¨¡å¼éƒ½æ˜¯ç›¸å¯¹å€¼ï¼Œå³ä¸­å¿ƒåæ ‡ç‚¹ç›¸å¯¹äºå·¦è¾¹ç•Œä¸Šè¾¹ç•Œä½äºæ•´å¼ å›¾ç‰‡çš„ä»€ä¹ˆä½ç½®ï¼ˆå–å€¼0~1ï¼‰
        """
        if len(labels):
            h, w = img.shape[:2]
            labels[:, [1, 3]] = labels[:, [1, 3]].clip(0, w - 1e-3)  # x1, x2
            labels[:, [2, 4]] = labels[:, [2, 4]].clip(0, h - 1e-3)  # y1, y2

            boxes = np.copy(labels[:, 1:])
            boxes[:, 0] = ((labels[:, 1] + labels[:, 3]) / 2) / w  # x center
            boxes[:, 1] = ((labels[:, 2] + labels[:, 4]) / 2) / h  # y center
            boxes[:, 2] = (labels[:, 3] - labels[:, 1]) / w  # width
            boxes[:, 3] = (labels[:, 4] - labels[:, 2]) / h  # height
            labels[:, 1:] = boxes

        if self.augment:
            img, labels = self.general_augment(img, labels)

        labels_out = torch.zeros((len(labels), 6))
        if len(labels):
            labels_out[:, 1:] = torch.from_numpy(labels)

        # Convert
        img = img.transpose((2, 0, 1))[::-1]  # HWC to CHW, BGR to RGB
        img = np.ascontiguousarray(img)

        return (torch.from_numpy(img).to(dtype=torch.float32),
                labels_out, self.img_paths[index], shapes)

    def get_images_and_labels(self, img_dir):
        """é¦–å…ˆå…ˆè·å–å›¾ç‰‡çš„è·¯å¾„ã€æ ‡ç­¾çš„è·¯å¾„ã€img_infoã€cache_info"""
        img_paths, label_paths, img_info, cache_info = self._get_img_and_label_list(img_dir)

        num_threads = min(12, os.cpu_count())  # å¤šçº¿ç¨‹å¤„ç†å›¾ç‰‡æ‰€è®¾å®šçš„çº¿ç¨‹æ•°

        # æŸ¥çœ‹æ˜¯å¦éœ€è¦æ£€éªŒå›¾ç‰‡è·¯å¾„æ–‡ä»¶
        if self.check_images and self.main_process:
            img_info = {}
            nc, msgs = 0, []
            with Pool(num_threads) as pool:
                pbar = tqdm(pool.imap(LoadImagesAndLabels.check_image, img_paths),
                            total=len(img_paths))
                for img_path, shape_per_img, nc_per_img, msg in pbar:
                    # å¦‚æœè¿”å›ç»“æœæ˜¾ç¤ºä¸ºï¼šå›¾ç‰‡æ— æŸåï¼Œåˆ™å‘img-infoä¸­æ·»åŠ å›¾ç‰‡çš„é«˜å®½ä¿¡æ¯
                    if nc_per_img == 0:
                        img_info[img_path] = {"shape": shape_per_img}
                    nc += nc_per_img
                    if msg:
                        msgs.append(msg)
            # nc è®°å½•æœ‰æ— å›¾ç‰‡æŸå num_corruption
            pbar.desc = f"{nc} image(s) corrupted"
            # å…³é—­tqdmè¿›åº¦æ¡
            pbar.close()
            cache_info = {"information": img_info, "image_hash": self.get_hash(img_paths)}
            # ä¿å­˜cacheä¿¡æ¯ï¼Œæ–¹ä¾¿ä¸‹æ¬¡å¿«é€Ÿæ£€æŸ¥
            with open(self.valid_img_record, "w") as f:
                json.dump(cache_info, f)

        # æŸ¥çœ‹æ˜¯å¦éœ€è¦æ£€éªŒæ ‡ç­¾è·¯å¾„æ–‡ä»¶
        if self.check_labels:
            cache_info["label_hash"] = self.get_hash(label_paths)  # å°†è®¡ç®—å¾—åˆ°çš„å“ˆå¸Œå€¼å­˜å…¥æ ‡ç­¾key
            nm, nf, ne, nc, msgs = 0, 0, 0, 0, []
            print(f"Checking formats of labels with {num_threads} processes:")
            with Pool(num_threads) as pool:
                pbar = tqdm(pool.imap(LoadImagesAndLabels.check_label_files,
                                      zip(img_paths, label_paths)),
                            total=len(label_paths))
                for (img_path, labels_per_file, nc_per_file, nm_per_file,
                     nf_per_file, ne_per_file, msg) in pbar:
                    if nc_per_file == 0:
                        # å¦‚æœç¡®è®¤è¯¥æ–‡ä»¶å¹¶æœªæŸåï¼Œå°†labelæ–‡ä»¶çš„æ ‡ç­¾å€¼æ·»åŠ åˆ°infoå­—å…¸ä¸­
                        img_info[img_path]["labels"] = labels_per_file
                    else:
                        # å¦‚æœlabelæ ‡ç­¾æ–‡ä»¶æŸåï¼Œåˆ™å°†å¯¹åº”çš„å›¾ç‰‡imgæ–‡ä»¶ä»å­—å…¸ä¸­åˆ å»
                        img_info.pop(img_path)
                    nc += nc_per_file
                    nm += nm_per_file
                    nf += nf_per_file
                    ne += ne_per_file
                    if msg:
                        msgs.append(msg)
                    pbar.desc = (f"{nf} label(s) found, {nm} label(s) missing, "
                                 f"{ne} label(s) empty, {nc} invalid label files")
            # æœ€åå…³é—­tqdmæ—¶é—´æ¨¡å—å¹¶ä¿å­˜imgä¸labelsçš„æ£€æŸ¥cacheä¿¡æ¯
            pbar.close()
            with open(self.valid_img_record, "w") as f:
                json.dump(cache_info, f)

        # å¦‚æœä»»åŠ¡æ˜¯æ„å»ºéªŒè¯æ•°æ®é›†ï¼š
        if self.task.lower() == 'val':
            self._build_annotations(img_dir=img_dir, img_info=img_info)

        img_paths, labels = list(
            zip(
                *[
                    (img_path,
                     np.array(info["labels"], dtype=np.float32)
                     if info["labels"] else np.zeros((0, 5), dtype=np.float32))
                    for img_path, info in img_info.items()  # å–å‡ºimg_infoæ‰€æœ‰çš„é”®å€¼å¯¹
                ]
            )
        )
        print(f"{self.task}: Final numbers of valid images: {len(img_paths)}/ labels: {len(labels)}. ")
        return img_paths, labels, img_info

    def _get_img_and_label_list(self, img_dir):
        assert osp.exists(img_dir), f"{img_dir} is an invalid directory path!"

        # é€’å½’åœ°éå†å‡ºæ‰€æœ‰å›¾ç‰‡æ–‡ä»¶çš„è·¯å¾„ï¼Œå¹¶å°†å…¶å­˜å‚¨åœ¨æ•°ç»„ä¸­
        print("ğŸ”ï¸Searching all the images...")
        start_time = time.time()
        img_paths = glob.glob(osp.join(img_dir, "**/*"), recursive=True)
        img_paths = [p for p in img_paths if p.split(".")[-1].lower() in IMG_FORMATS and os.path.isfile(p)]
        end_time = time.time()
        print("âœ…Searching completed in {:.2f}s".format(end_time - start_time))

        assert img_paths, f"No images found in {img_dir}!"

        # ä»¥ä¸‹å¼€å§‹æœç´¢æ‰€æœ‰çš„æ ‡ç­¾æ–‡ä»¶è·¯å¾„ï¼Œå¹¶å°†å…¶å­˜å‚¨åœ¨æ•°ç»„ä¸­
        label_dir = osp.join(
            osp.dirname(osp.dirname(img_dir)), "labels", osp.basename(img_dir)
        )  # coco\labels\train2017
        assert osp.exists(label_dir), f"{label_dir} is an invalid directory path!"

        label_paths = [osp.join(str(label_dir), osp.splitext(osp.basename(p))[0]+'.txt')
                       for p in img_paths]
        assert label_paths, f"No labels found in {label_dir}."

        # æ„å»ºç¼“å­˜æ–‡ä»¶çš„è·¯å¾„
        """
        è¿™é‡Œçš„ img_info å­˜å‚¨çš„ä¿¡æ¯æ˜¯æ¯ä¸€å¼ å›¾ç‰‡çš„ç›¸å¯¹è·¯å¾„ï¼Œä»¥åŠå¯¹åº”çš„å°ºå¯¸å’Œæ ‡ç­¾å€¼
        å…¶ç»“æ„ä¸ºï¼šé”®-å€¼å¯¹æ¨¡å¼ï¼Œkey==img_pathï¼Œvalue=={shape, labels}
        å…¶ä¸­ï¼Œshapeå’Œlabelsäº¦ä¸ºé”®å€¼å¯¹æ ¼å¼ï¼Œshape == [height, width]ï¼Œ
        labels == [[class, å·¦ä¸Šæ¨ªåæ ‡ï¼Œå·¦ä¸Šçºµåæ ‡ï¼Œå³ä¸‹æ¨ªåæ ‡ï¼Œå³ä¸‹çºµåæ ‡], ...] äºŒç»´æ•°ç»„
        """
        print('Building cache path......')
        cache_info = {}
        img_info = {}
        valid_img_record = osp.join(
            osp.dirname(img_dir), "." + osp.basename(img_dir) + ".json"
        )
        self.valid_img_record = valid_img_record
        img_hash = self.get_hash(img_paths)
        label_hash = self.get_hash(label_paths)
        if osp.exists(valid_img_record):
            print('Cache file exists, now loading...')
            with open(valid_img_record, 'r') as f:
                cache_info = json.load(f)
                if "image_hash" in cache_info and cache_info["image_hash"] == img_hash:
                    img_info = cache_info["information"]
                    if "label_hash" not in cache_info or cache_info["label_hash"] != label_hash:
                        self.check_labels = True
                else:
                    self.check_images, self.check_labels = True, True
        else:
            print(f'Cache file {valid_img_record} does not exist, '
                  f'need to check images and labels...')
            self.check_images, self.check_labels = True, True

        return img_paths, label_paths, img_info, cache_info

    def _build_annotations(self, img_dir, img_info):
        """æ£€æŸ¥data_dictä¸­æ˜¯å¦æœ‰is_coco, æ²¡æœ‰çš„è¯å°±åˆ›å»ºå¹¶å­˜å‚¨annotations"""
        if self.data_dict.get("is_coco", False):
            assert osp.exists(self.data_dict["anno_path"]), \
                ("Eval on coco dataset must provide valid path "
                 "of the annotation file in config file: data/coco.yaml")
            print(f"anno path {self.data_dict['anno_path']} already exists!")
        else:
            assert self.class_name, \
                "Class names is required when converting labels to coco format for evaluating."
            save_dir = osp.join(osp.dirname(osp.dirname(img_dir)), "annotations")
            if not osp.exists(save_dir):
                os.mkdir(save_dir)
            save_path = osp.join(
                # å¾—åˆ°çš„annotationsä¿å­˜è·¯å¾„ä¸º: /coco/annotations/instances_val2017.json
                save_dir, "instance_" + osp.basename(img_dir) + ".json")
            print(f"anno path dose not exists! now creating annotations in {save_path}")
            t1 = time.time()
            LoadImagesAndLabels.generate_coco_format_labels(
                img_info=img_info, class_names=self.class_name, save_path=save_path
            )
            t2 = time.time()
            print("{:.2f}s for generating COCO format labels.".format(t2 - t1))

    def sort_files_shapes(self):
        """
        è¯¥å‡½æ•°çš„ä½œç”¨å’Œå¥½å¤„ï¼š
        1-æ›´å‡åŒ€çš„æ‰¹æ¬¡å½¢çŠ¶åˆ†å¸ƒï¼š
            é€šè¿‡æ ¹æ®å›¾ç‰‡çš„é«˜å®½æ¯”æ¥ç¡®å®šæ¯ä¸ªæ‰¹æ¬¡è®­ç»ƒå›¾ç‰‡çš„å½¢çŠ¶ï¼Œå¯ä»¥å°½é‡ä¿è¯æ¯ä¸ªæ‰¹æ¬¡ä¸­çš„å›¾ç‰‡
            å½¢çŠ¶ç›¸ä¼¼ã€‚è¿™æ ·å¯ä»¥é¿å…åœ¨è®­ç»ƒè¿‡ç¨‹ä¸­å‡ºç°å½¢çŠ¶å·®å¼‚è¿‡å¤§çš„æƒ…å†µï¼Œæœ‰åŠ©äºå‡å°‘æ‰¹æ¬¡ä¹‹é—´çš„
            å·®å¼‚æ€§ï¼Œæé«˜è®­ç»ƒçš„ç¨³å®šæ€§ã€‚
        2-æœ€å¤§ç¨‹åº¦åœ°åˆ©ç”¨è®¡ç®—èµ„æº
            å°†å½¢çŠ¶ç›¸ä¼¼çš„å›¾ç‰‡æ”¾åœ¨åŒä¸€ä¸ªæ‰¹æ¬¡ä¸­è¿›è¡Œè®­ç»ƒï¼Œå¯ä»¥æœ€å¤§ç¨‹åº¦åœ°åˆ©ç”¨è®¡ç®—èµ„æºï¼Œå‡å°‘åœ¨
            å¤„ç†ä¸åŒå›¾ç‰‡æ—¶çš„è®¡ç®—èµ„æºçš„æµªè´¹ã€‚è¿™æ ·å¯ä»¥æé«˜è®­ç»ƒæ•ˆç‡ï¼ŒåŠ é€Ÿæ¨¡å‹æ”¶æ•›é€Ÿåº¦ã€‚
        3-å‡å°‘å†…å­˜å ç”¨å’Œæ•°æ®åŠ è½½æ—¶é—´
            ç»è¿‡å½¢çŠ¶è°ƒæ•´åçš„å›¾ç‰‡å¯ä»¥æ›´å¥½åœ°é€‚åº”æ¨¡å‹çš„è¾“å…¥è¦æ±‚ï¼Œä»è€Œå‡å°‘å†…å­˜å ç”¨å’Œæ•°æ®åŠ è½½
            æ—¶é—´ã€‚è¿™å¯¹äºå¤„ç†å¤§è§„æ¨¡æ•°æ®é›†æ—¶å°¤ä¸ºé‡è¦ï¼Œå¯ä»¥å‡å°‘æ•°æ®é¢„å¤„ç†æ—¶é—´ï¼Œæé«˜è®­ç»ƒé€Ÿåº¦ã€‚
        """
        # è®¡ç®—è¿™æ‰¹æ•°æ®é›†å…±æœ‰å¤šå°‘ä¸ªæ‰¹æ¬¡(batch)
        batch_num = self.batch_indices[-1] + 1
        s = self.shapes  # åŸå§‹å›¾ç‰‡çš„ height å’Œ width

        aspect_ratio = s[:, 1] / s[:, 0]  # å®½é«˜æ¯”=width/height

        # å°†é«˜å®½æ¯”æŒ‰ç…§ä»å°åˆ°å¤§çš„é¡ºåºæ’åˆ—ï¼Œå¹¶å¾—åˆ°æ’åˆ—åçš„åŸå§‹ç´¢å¼•å€¼index
        index_rect = aspect_ratio.argsort()

        # æŒ‰ç…§é«˜å®½æ¯”ä»å°åˆ°å¤§çš„ç´¢å¼•é‡æ–°åŠ è½½å›¾ç‰‡æ•°æ®çš„é¡ºåº
        self.img_paths = [self.img_paths[i] for i in index_rect]

        # æŒ‰ç…§é«˜å®½æ¯”ä»å°åˆ°å¤§çš„ç´¢å¼•é‡æ–°åŠ è½½å›¾ç‰‡æ ‡ç­¾æ•°æ®çš„é¡ºåº
        self.labels = [self.labels[i] for i in index_rect]

        # å½¢çŠ¶ä¿¡æ¯ä¹Ÿé‡æ–°æ’åˆ—
        self.shapes = s[index_rect]
        # è·å¾—ä»å°åˆ°å¤§æ’åˆ—çš„é«˜å®½æ¯”aspect_ratio
        aspect_ratio = aspect_ratio[index_rect]

        # è®¾ç½®è®­ç»ƒå›¾ç‰‡çš„å½¢çŠ¶
        shapes = [[1, 1]] * batch_num
        for i in range(batch_num):
            # -----------------------------------------------------------------------------
            # ç„¶åå†æŒ‰ç…§æ‰¹æ¬¡å·å»å–å‡ºä¸€æ•´ä¸ªæ‰¹æ¬¡çš„æ‰€æœ‰å›¾ç‰‡çš„é«˜å®½æ¯”ï¼š
            #       aspect_ratio_index.shape = [batch_size]ï¼Œè¡¨ç¤ºçš„æ˜¯æ¯ä¸ªæ‰¹æ¬¡ä¸­ï¼Œæ¯ä¸€å¼ å›¾ç‰‡çš„é«˜å®½
            #       æ¯”ï¼Œæ¯”å¦‚ä¸€ä¸ªæ‰¹æ¬¡çš„å›¾ç‰‡æ•°é‡ batch_size=8ï¼Œå› æ­¤ä¸€æ¬¡é€‰å‡ºçš„ aspect_ratio_index çš„é•¿
            #       åº¦å°±æ˜¯ 8ï¼Œæ¯ä¸€ä¸ªå€¼éƒ½è¡¨ç¤ºä¸€å¼ å›¾ç‰‡çš„é«˜å®½æ¯”
            # -----------------------------------------------------------------------------
            aspect_ratio_index = aspect_ratio[self.batch_indices == i]

            # -----------------------------------------------------------------------------
            # é€‰å‡ºè¿™ä¸ªæ‰¹æ¬¡ä¸­çš„æœ€å¤§é«˜å®½æ¯”ã€æœ€å°é«˜å®½æ¯”ï¼š
            #       1. aspect_ratio_index.min() è¡¨ç¤ºå–å‡ºä¸€ä¸ªæ‰¹æ¬¡ä¸­æ‰€æœ‰å›¾ç‰‡çš„æœ€å°minçš„é«˜å®½æ¯”å€¼
            #       2. aspect_ratio_index.max() è¡¨ç¤ºå–å‡ºä¸€ä¸ªæ‰¹æ¬¡ä¸­æ‰€æœ‰å›¾ç‰‡çš„æœ€å¤§maxçš„é«˜å®½æ¯”å€¼
            # -----------------------------------------------------------------------------
            minimum, maximum = aspect_ratio_index.min(), aspect_ratio_index.max()

            if maximum < 1:
                """
                å¦‚æœæœ€å¤§å®½/é«˜æ¯”å°äº1ï¼Œå°±è®¾ç½®è¿™ä¸ªæ‰¹æ¬¡çš„æ‰€æœ‰å›¾ç‰‡çš„ç›¸å¯¹æ¯”ä¾‹ä¸º [1, maximum]
                æ³¨æ„ï¼š
                    shape[0]=height, shape[1]=width, å›¾ç‰‡shapeçš„ç¬¬ä¸€ç»´åº¦è¡¨ç¤ºheighté«˜ï¼Œ ç¬¬äºŒç»´åº¦è¡¨ç¤ºwidthå®½
                    å› æ­¤ï¼Œå½“è¿™ä¸€æ‰¹æ¬¡çš„å›¾ç‰‡ä¸­ï¼Œæœ€å¤§çš„å®½/é«˜æ¯”ä¹Ÿå°äº 1ï¼Œåˆ™è¯´æ˜è¿™ä¸€æ‰¹æ¬¡çš„å›¾ç‰‡å…¨éƒ¨éƒ½æ˜¯é«˜å¤§äºå®½ï¼Œå› æ­¤å°†è¿™ä¸€æ‰¹
                    æ¬¡çš„ç»Ÿä¸€å½¢çŠ¶æ¯”ä¾‹è®¾ç½®ä¸º [1, maximum]
                """
                shapes[i] = [1, maximum]  # maximum = height / width
            elif minimum > 1:
                """
                å¦‚æœæœ€å°é«˜å®½æ¯”å¤§äº1ï¼Œå°±è®¾ç½®è¿™ä¸ªæ‰¹æ¬¡çš„æ‰€æœ‰å›¾ç‰‡çš„ç›¸å¯¹æ¯”ä¾‹ä¸º [1/minimum, 1]
                æ³¨æ„ï¼š
                    shape[0]=height, shape[1]=width, å›¾ç‰‡shapeçš„ç¬¬ä¸€ç»´åº¦è¡¨ç¤ºheighté«˜ï¼Œç¬¬äºŒç»´åº¦è¡¨ç¤ºwidthå®½ï¼Œ
                    å› æ­¤ï¼Œå½“è¿™ä¸€æ‰¹æ¬¡çš„å›¾ç‰‡ä¸­ï¼Œæœ€å°çš„å®½/é«˜æ¯”è¦å¤§äº 1ï¼Œåˆ™è¯´æ˜è¿™ä¸€æ‰¹æ¬¡çš„æ‰€æœ‰å›¾ç‰‡éƒ½æ˜¯å®½å¤§äºé«˜çš„ï¼Œå› æ­¤è¿™ä¸€
                    æ‰¹æ¬¡çš„ç»Ÿä¸€å½¢çŠ¶æ¯”ä¾‹è®¾ç½®ä¸º [1 / minimum, 1]
                """
                shapes[i] = [1 / minimum, 1]  # minimum = width / height

        batch_shapes = (
            np.ceil(
                # æŠŠåˆ¶ä½œå¥½çš„æ‰¹æ¬¡å›¾ç‰‡å½¢çŠ¶æ¯”ä¾‹
                np.array(shapes) * self.img_size / self.stride + self.pad
            ).astype(np.int_) * self.stride
        )
        return batch_shapes

    def load_image(self, index, force_load_size=None):
        """
        åŠ è½½å›¾ç‰‡
        è¯¥å‡½æ•°é€šè¿‡cv2æ¥è¿›è¡Œå›¾ç‰‡åŠ è½½ï¼Œå¯¹åŸå§‹å›¾ç‰‡è¿›è¡Œå¤§å°è°ƒæ•´ï¼ˆä¿æŒåŸæœ‰çš„é«˜å®½æ¯”ï¼‰
        Returns:
            Imageå›¾ç‰‡ï¼Œå›¾ç‰‡çš„åŸå§‹å°ºå¯¸ï¼Œæ›´æ”¹åçš„å›¾ç‰‡å°ºå¯¸
        """
        path = self.img_paths[index]
        try:
            im = cv2.imread(path)
            assert im is not None, f"opencv cannot read image correctly or {path} not exists"
        except Warning as warning:
            im = cv2.cvtColor(np.asarray(Image.open(path)), cv2.COLOR_RGB2BGR)
            assert im is not None, f"Image Not Found {path}, workdir: {os.getcwd()}"

        """
        cv2è¯»å–å›¾ç‰‡çš„æ ¼å¼æ˜¯ Height-Width-Channels
        æœ€åä¸€ç»´è¡¨ç¤ºå›¾ç‰‡é€šé“æ•°ï¼Œå› æ­¤åªéœ€è¦å–å‰ä¸¤ä½é«˜å®½å³å¯
        """
        h0, w0 = im.shape[:2]  # åŸå§‹å›¾ç‰‡å°ºå¯¸
        # ------------------------------------------------------------------------------------
        # rè¡¨ç¤ºæŒ‡å®šçš„img_sizeä¸å®é™…å›¾ç‰‡ä¹‹é—´çš„æ¯”ä¾‹å…³ç³»
        # r < 1 è¡¨ç¤ºåŸå§‹å›¾ç‰‡è¾ƒé•¿è¾¹å¤§äºæŒ‡å®šå¤§å°img_sizeï¼Œæ­¤æ—¶éœ€è¦ç¼©å°æ“ä½œ(å›¾ç‰‡ç­‰æ¯”ä¾‹ç¼©å°åˆ°è¾ƒé•¿è¾¹ç­‰äºimg_size)
        # r > 1 è¡¨ç¤ºåŸå§‹å›¾ç‰‡è¾ƒé•¿è¾¹å°äºæŒ‡å®šå¤§å°img_sizeï¼Œæ­¤æ—¶éœ€è¦å¢å¤§æ“ä½œ(å›¾ç‰‡ç­‰æ¯”ä¾‹æ‰©å¤§åˆ°è¾ƒé•¿è¾¹ç­‰äºing_size)
        # ------------------------------------------------------------------------------------
        if force_load_size:
            ratio = force_load_size / max(h0, w0)
        else:
            ratio = self.img_size / max(h0, w0)
        if ratio != 1:
            im = cv2.resize(
                im,
                dsize=(int(w0 * ratio), int(h0 * ratio)),
                interpolation=cv2.INTER_AREA  # å›¾ç‰‡ç¼©å°ç”¨åŒºé—´æ’å€¼
                if ratio < 1 and not self.augment else cv2.INTER_LINEAR)  # å›¾ç‰‡å¢å¤§ç”¨çº¿æ€§æ’å€¼
        return im, (h0, w0), im.shape[:2]

    def general_augment(self, img, labels):
        """
        è·å–ç»è¿‡å›¾ç‰‡å¢å¼ºæ“ä½œåçš„imageså’Œlabels
        è¯¥å‡½æ•°çš„ä¸»è¦å¢å¼ºæ¨¡å¼æ˜¯ï¼šhsvé¢œè‰²æ”¹å˜ï¼Œéšæœºå‚ç›´ç¿»è½¬ï¼Œéšæœºæ°´å¹³ç¿»è½¬
        """
        num_labels = len(labels)

        # HSV color-space
        augment_hsv(img,
                    h_gain=self.hyp["hsv_h"],
                    s_gain=self.hyp["hsv_s"],
                    v_gain=self.hyp["hsv_v"])

        # Flip up-down å‚ç›´ç¿»è½¬
        if random.random() < self.hyp["flipud"]:
            img = np.flipud(img)
            if num_labels:
                # å›¾åƒç¿»è½¬äº†ï¼Œlabelsæ ‡è®°çš„ç›®æ ‡çš„é”šæ¡†åæ ‡ä½ç½®ä¹Ÿåˆ«å¿˜è®°ç¿»è½¬ï¼
                labels[:, 2] = 1 - labels[:, 2]

        # Flip left-right æ°´å¹³ç¿»è½¬
        if random.random() < self.hyp["fliplr"]:
            img = np.fliplr(img)
            if num_labels:
                labels[:, 1] = 1 - labels[:, 1]

        return img, labels

    def get_mosaic(self, index):
        """è·å–ç»è¿‡é©¬èµ›å…‹å›¾ç‰‡å¢å¼ºçš„å›¾ç‰‡ä»¥åŠæ ‡ç­¾å€¼"""
        indices = [index] + random.choices(
            range(0, len(self.img_paths)), k=3
        )  # å› ä¸ºé©¬èµ›å…‹å¢å¼ºéœ€è¦å››å¼ å›¾ç‰‡æ‹¼åœ¨ä¸€èµ·ï¼Œå› æ­¤è¿™é‡Œé™¤äº†å·²ç»æä¾›çš„indexå¤–ï¼Œè¿˜éœ€é¢å¤–å†éšæœºé€‰ä¸‰å¼ 
        random.shuffle(indices)
        images, hs, ws, labels = [], [], [], []
        for index in indices:
            # åœ¨å›¾ç‰‡åŠ è½½çš„è¿‡ç¨‹å°±å·²ç»å®Œæˆäº†å°†åŸå§‹å›¾ç‰‡resizeåˆ°è¾ƒé•¿è¾¹å°äºç­‰äºç»™å®šå°ºå¯¸img_size
            im, _, (h, w) = self.load_image(index)
            labels_per_img = self.labels[index]
            images.append(im)
            hs.append(h)
            ws.append(w)
            labels.append(labels_per_img)
        images, labels = mosaic_augmentation(self.img_size, images, hs, ws, labels, self.hyp)
        return images, labels

    def _rect_shape_process(self):
        shapes = [self.img_info[p]["shape"] for p in self.img_paths]

    @staticmethod
    def collate_fn(batch):
        """Merges a list of samples to form a mini-batch of Tensor(s)"""
        # --------------------------------------------------------------
        # collate_fn çš„ä½œç”¨æ˜¯åœ¨åˆ›å»ºDataLoaderçš„è¿‡ç¨‹ä¸­ï¼Œæä¾›ä¸€ç§å¯¹äºæ¯ä¸ªmini-batch
        # è¿›è¡Œæ›´åŠ ç»†è‡´çš„é¢„å¤„ç†çš„æ–¹æ³•ï¼Œåœ¨æœ¬ä¾‹ä¸­æä¾›çš„å¤„ç†æ–¹æ³•æ˜¯ï¼Œå¯¹äºæ¯ä¸ªbatchçš„æ¯å¼ å›¾ç‰‡
        # å¯¹åº”labelsï¼Œéƒ½åœ¨ç¬¬ä¸€ç»´åº¦æ’å…¥å¯¹åº”å›¾ç‰‡çš„indexç´¢å¼•å€¼
        # ---------------------------------------------------------------
        img, label, path, shapes = zip(*batch)
        for i, l in enumerate(label):
            l[:, 0] = i  # ä¸ºåˆ›å»ºæ ‡ç­¾æ·»åŠ ç›®æ ‡å›¾ç‰‡çš„ç´¢å¼•å€¼
        return torch.stack(img, 0), torch.cat(label, 0), path, shapes

    @staticmethod
    def get_hash(paths):
        """è·å–è·¯å¾„çš„å“ˆå¸Œå€¼"""
        assert isinstance(paths, list), "Only support list currently."
        h = hashlib.md5("".join(paths).encode())
        return h.hexdigest()

    @staticmethod
    def check_image(img_file):
        """éªŒè¯å›¾ç‰‡"""
        nc, msg = 0, ""
        try:
            img = Image.open(img_file)
            img.verify()
            img = Image.open(img_file)
            shape = (img.height, img.width)  # !!!PILçš„è¯»å–æ˜¯(width, height)
            try:
                img_exif = img.getexif()
                if img_exif and orientation in img_exif:
                    rotation = img_exif[orientation]
                    if rotation in (6, 8):
                        shape = (shape[1], shape[0])
            except ValueError:
                img_exif = None

            assert (shape[0] > 9) and (shape[1] > 9), f"image size {shape} < 10 pixels"
            assert img.format.lower() in IMG_FORMATS, f"invalid image format {img.format}!"
            if img.format.lower() in ("jpg", "jpeg"):
                with open(img_file, "rb") as f:
                    f.seek(-2, 2)
                    if f.read() != b"\xff\xd9":
                        ImageOps.exif_transpose(Image.open(img_file)).save(
                            img_file, "JPEG", subsampling=0, quality=100
                        )
                        msg += f"WARNING: {img_file}: corrupt JPEG restored and saved!"
            return img_file, shape, nc, msg

        except Exception as e:
            nc = 1
            msg = f"WARNING: {img_file}: ignoring corrupt image:{e}"
            return img_file, None, nc, msg

    @staticmethod
    def check_label_files(path_args):
        # åˆ†åˆ«ä¸ºå•ä¸ªå›¾ç‰‡jpgæ–‡ä»¶çš„è·¯å¾„ï¼Œä»¥åŠå•ä¸ªå¯¹åº”æ ‡ç­¾txtæ–‡ä»¶çš„è·¯å¾„
        img_path, label_path = path_args
        nm, nf, ne, nc, msg = 0, 0, 0, 0, ""  # number (missing found empty message)
        try:
            if osp.exists(label_path):
                nf = 1  # label found æ ‡è®°ä¸ºæ‰¾åˆ°labelæ–‡ä»¶
                with open(label_path, "r") as f:
                    # è¯»å–æ‰“å¼€labelæ ‡ç­¾æ–‡ä»¶ï¼Œæ ‡ç­¾æ–‡ä»¶æ ¼å¼ä¸º [ç±»åˆ«ï¼Œå·¦ä¸Šè§’xï¼Œå·¦ä¸Šè§’yï¼Œå³ä¸‹è§’xï¼Œå³ä¸‹è§’y]
                    labels = [
                        x.split() for x in f.read().strip().splitlines() if len(x)
                    ]
                    # è¯»å–txtæ–‡ä»¶å†…å®¹ï¼Œå¹¶å°†æ ‡ç­¾labelè½¬æ¢æˆnumpyæ•°ç»„æ ¼å¼
                    labels = np.array(labels, dtype=np.float32)

                # ç»è¿‡å¤„ç†åçš„ä¸€ä¸ªæ ‡ç­¾æ–‡ä»¶çš„labelsæ•°ç»„ä¸­åº”è¯¥æ˜¯æœ‰é•¿åº¦çš„(>=1)
                if len(labels):
                    """ä¸€ä¸ªæ ‡ç­¾txtæ–‡ä»¶äº§ç”Ÿçš„labelsæ•°ç»„ä¸­çš„æ¯ä¸ªå…ƒç´ ä¹Ÿæ˜¯æ•°ç»„ï¼Œå¹¶ä¸”é•¿åº¦ä¸€å®šè¦æ˜¯5"""
                    assert all(
                        len(l) == 5 for l in labels
                    ), f"{label_path}: wrong label format."  # å¦‚æœlabelsæ•°ç»„ä¸­çš„å…ƒç´ å­˜åœ¨é•¿åº¦ä¸æ˜¯5çš„ï¼Œæ ¼å¼é”™è¯¯

                    """ç¬¬äºŒæ­¥ï¼šæ£€æŸ¥æ‰€æœ‰çš„æ ‡ç­¾å€¼éƒ½è¦å¤§äºç­‰äº0"""
                    assert (
                            labels >= 0
                    ).all(), f"{label_path}: Label values error: all values in label file must > 0"

                    """ç¬¬ä¸‰æ­¥ï¼šæ£€æŸ¥æ‰€æœ‰çš„å››è§’åæ ‡éƒ½è¦è¢«æ ‡å‡†åŒ–ï¼Œå–å€¼ä½äº0~1ä¹‹é—´"""
                    assert (
                            labels[:, 1:] <= 1
                    ).all(), f"{label_path}: Label values error: all coordinates must be normalized"

                    """ç¬¬å››æ­¥ï¼šæ£€æŸ¥æœ‰æ²¡æœ‰æ ‡ç­¾å€¼é‡å¤çš„æƒ…å†µ"""
                    _, indices = np.unique(labels, axis=0, return_index=True)
                    if len(indices) < len(labels):
                        labels = labels[indices]
                        msg += f"WARNING: {label_path}: {len(labels) - len(indices)} duplicate labels removed"
                    labels = labels.tolist()
                else:
                    ne = 1  # æ ‡ç­¾åˆ—è¡¨ä¸ºç©º label empty
                    labels = []
            else:
                nm = 1  # æ ‡ç­¾åˆ—è¡¨æœªæ‰¾åˆ° label missing
                labels = []

            return img_path, labels, nc, nm, nf, ne, msg
        except Exception as e:
            nc = 1
            msg = f"WARNING: {label_path}: ignoring invalid labels: {e}"
            return img_path, None, nc, nm, nf, ne, msg

    @staticmethod
    def generate_coco_format_labels(img_info, class_names, save_path):
        """ä½¿ç”¨pycocotoolsæ„å»ºéªŒè¯é›†"""
        dataset = {"categories": [], "annotations": [], "images": []}
        for i, class_name in enumerate(class_names):
            dataset["categories"].append(
                {"id": i, "name": class_name, "supercategories": ""}
            )
        ann_id = 0
        print("Converting to COCO format dataset...")
        for i, (img_path, info) in enumerate(tqdm(img_info.items())):
            labels = info["labels"] if info["labels"] else []
            img_id = osp.splitext(osp.basename(img_path))[0]
            img_w, img_h = info["shape"]
            dataset["images"].append(
                {
                    "file_name": os.path.basename(img_path),
                    "id": img_id,
                    "width": img_w,
                    "height": img_h
                }
            )
            if labels:
                for label in labels:
                    c, x, y, w, h = label[:5]
                    # æŠŠä¸­å¿ƒåæ ‡-å®½é«˜æ¨¡å¼æ›´æ”¹ä¸ºå¯¹ç„¦åæ ‡æ¨¡å¼([x,y,w,h]-->[x1,y1,x2,y2])
                    x1 = (x - w / 2) * img_w
                    y1 = (y - h / 2) * img_h
                    x2 = (x + w / 2) * img_w
                    y2 = (y + h / 2) * img_h
                    # cls_id ç±»åˆ«æ ‡ç­¾ä» 0 å¼€å§‹
                    cls_id = int(c)
                    w = max(0, x2 - x1)
                    h = max(0, y2 - y1)
                    dataset["annotations"].append(
                        {
                            "area": h * w,
                            "bbox": [x1, y1, w, h],
                            "category_id": cls_id,
                            "id": ann_id,
                            "image_id": img_id,
                            "iscrowd": 0,
                            "segmentation": []
                        }
                    )
                    ann_id += 1
        # æ•´ä¸ªcocoæ ¼å¼éªŒè¯æ•°æ®æ„å»ºå®Œæˆåï¼Œå†™å…¥jsonæ–‡ä»¶
        with open(save_path, "w") as f:
            json.dump(dataset, f)


class LoadData:
    def __init__(self, path, webcam, webcam_addr):
        self.webcam = webcam
        self.webcam_addr = webcam_addr
        if webcam:
            img_path = []
            video_path = [int(webcam_addr) if webcam_addr.isdigit() else webcam_addr]
        else:
            path = str(Path(path).resolve())
            if os.path.isdir(path):
                files = sorted(glob.glob(os.path.join(path, '**/*.*'), recursive=True))
            elif os.path.isfile(path):
                files = [path]
            else:
                raise FileNotFoundError(f'Invalid path {path}')

            img_path = [i for i in files if i.split('.')[-1] in IMG_FORMATS]
            video_path = [v for v in files if v.split('.')[-1] in VID_FORMATS]

        self.files = img_path + video_path
        self.num_files = len(self.files)
        self.type = 'image'

        self.frames, self.frame = None, None

        if len(video_path) > 0:
            self.add_video(video_path[0])
        else:
            self.cap = None

    def __iter__(self):
        self.count = 0
        return self

    def __next__(self):
        if self.count == self.num_files:
            raise StopIteration
        path = self.files[self.count]
        if self.check_ext(path) == 'video':
            self.type = 'video'
            ret_val, img = self.cap.read()
            while not ret_val:
                self.count += 1
                self.cap.release()
                if self.count == self.num_files:
                    raise StopIteration
                path = self.files[self.count]
                self.add_video(path)
                ret_val, img = self.cap.read()
        else:
            self.count += 1
            img = cv2.imread(path)  # cv2çš„è¯»å–é¡ºåºæ˜¯ BGR
        return img, path, self.cap

    def add_video(self, path):
        self.frame = 0
        self.cap = cv2.VideoCapture(path)
        self.frames = int(self.cap.get(cv2.CAP_PROP_FRAME_COUNT))

    def check_ext(self, path):
        """
        æ£€æµ‹æ–‡ä»¶ç±»å‹ï¼Œåˆ°åº•æ˜¯è§†é¢‘æ ¼å¼ã€è¿˜æ˜¯å›¾ç‰‡æ ¼å¼çš„æ¨ç†æ•°æ®
        """
        if self.webcam:
            file_type = 'video'
        else:
            file_type = 'image' if path.split('.')[-1].lower() in IMG_FORMATS else 'video'
        return file_type

